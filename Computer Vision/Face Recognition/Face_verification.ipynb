{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bdbb4148",
   "metadata": {},
   "source": [
    "# Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a7617167",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import uuid\n",
    "import matplotlib.pyplot as plt\n",
    "from config import CWD, DATA_PATH, ANC_PATH, POS_PATH, NEG_PATH\n",
    "\n",
    "# Import tensorflow dependencies - Functional API\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.applications import VGG16\n",
    "from tensorflow.keras.layers import Layer, Conv2D, Dense, MaxPooling2D, Input, Flatten\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d7e7e9d",
   "metadata": {},
   "source": [
    "# Data Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8617147",
   "metadata": {},
   "source": [
    "### Data augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9f3a7e90",
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_aug(img):\n",
    "    data = []\n",
    "    for i in range(9):\n",
    "        img = tf.image.stateless_random_brightness(img, max_delta=0.02, seed=(1,2))\n",
    "        img = tf.image.stateless_random_contrast(img, lower=0.6, upper=1, seed=(1,3))\n",
    "        img = tf.image.stateless_random_flip_left_right(img, seed=(np.random.randint(100),np.random.randint(100)))\n",
    "        img = tf.image.stateless_random_jpeg_quality(img, min_jpeg_quality=90, max_jpeg_quality=100, seed=(np.random.randint(100),np.random.randint(100)))\n",
    "        img = tf.image.stateless_random_saturation(img, lower=0.9,upper=1, seed=(np.random.randint(100),np.random.randint(100)))\n",
    "\n",
    "        data.append(img)\n",
    "    \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1230d4fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "for file_name in os.listdir(os.path.join(POS_PATH)):\n",
    "    img_path = os.path.join(POS_PATH, file_name)\n",
    "    img = cv2.imread(img_path)\n",
    "    augmented_images = data_aug(img) \n",
    "    \n",
    "    for image in augmented_images:\n",
    "        cv2.imwrite(os.path.join(POS_PATH, '{}.jpg'.format(uuid.uuid1())), image.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d03c9b4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "for file_name in os.listdir(os.path.join(ANC_PATH)):\n",
    "    img_path = os.path.join(ANC_PATH, file_name)\n",
    "    img = cv2.imread(img_path)\n",
    "    augmented_images = data_aug(img) \n",
    "    \n",
    "    for image in augmented_images:\n",
    "        cv2.imwrite(os.path.join(POS_PATH, '{}.jpg'.format(uuid.uuid1())), image.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9f5734dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get Image Directories\n",
    "anchor_paths = tf.data.Dataset.list_files(ANC_PATH+'\\*.jpg').take(3000)\n",
    "positive_paths = tf.data.Dataset.list_files(POS_PATH+'\\*.jpg').take(3000)\n",
    "negative_paths = tf.data.Dataset.list_files(NEG_PATH+'\\*.jpg').take(3000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43264b64",
   "metadata": {},
   "outputs": [],
   "source": [
    "dir_test = anchor_paths.as_numpy_iterator()\n",
    "print(dir_test.next())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "af34586f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Labelled Dataset\n",
    "positives = tf.data.Dataset.zip((anchor_paths, positive_paths, tf.data.Dataset.from_tensor_slices(tf.ones(len(anchor_paths)))))\n",
    "negatives = tf.data.Dataset.zip((anchor_paths, negative_paths, tf.data.Dataset.from_tensor_slices(tf.zeros(len(anchor_paths)))))\n",
    "data = positives.concatenate(negatives)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b2302efc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(b'D:\\\\face_verification\\\\data\\\\anchor\\\\f45baea0-ea6b-11ec-8632-bc542fd709a0.jpg',\n",
       " b'D:\\\\face_verification\\\\data\\\\positive\\\\0123b082-ea75-11ec-b412-bc542fd709a0.jpg',\n",
       " 1.0)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "samples = data.as_numpy_iterator()\n",
    "example = samples.next()\n",
    "example"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cae2602",
   "metadata": {},
   "source": [
    "### Scale and Resize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a8bc6083",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(file_path):\n",
    "    \n",
    "    # Read in image from file path\n",
    "    byte_img = tf.io.read_file(file_path)\n",
    "    # Load in the image \n",
    "    img = tf.io.decode_jpeg(byte_img)\n",
    "    \n",
    "    # Preprocessing steps - resizing the image to be 224*224*3\n",
    "    img = tf.image.resize(img, (224,224))\n",
    "    # Scale image to be between 0 and 1 \n",
    "    img = img / 255.0\n",
    "\n",
    "    # Return image\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f191f316",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_twin(input_img, validation_img, label):\n",
    "    return(preprocess(input_img), preprocess(validation_img), label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6820726a",
   "metadata": {},
   "outputs": [],
   "source": [
    "res = preprocess_twin(*example)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8bc6bf9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.imshow(res[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0db25267",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res[2]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea0fb6ee",
   "metadata": {},
   "source": [
    "# Build dataloader pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ce655138",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build dataloader pipeline\n",
    "data = data.map(preprocess_twin)\n",
    "data = data.cache()\n",
    "data = data.shuffle(buffer_size=10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "990d0330",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training partition\n",
    "train_data = data.take(round(len(data)*.7))\n",
    "train_data = train_data.batch(16)\n",
    "train_data = train_data.prefetch(8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b0f55c39",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testing partition\n",
    "test_data = data.skip(round(len(data)*.7))\n",
    "test_data = test_data.take(round(len(data)*.3))\n",
    "test_data = test_data.batch(16)\n",
    "test_data = test_data.prefetch(8)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1376745e",
   "metadata": {},
   "source": [
    "# Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56310279",
   "metadata": {},
   "source": [
    "## Image encodings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "71cde7ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "def image_encodings():\n",
    "    \n",
    "    model = VGG16(include_top=True, weights='imagenet')\n",
    "    model = Model(inputs = model.inputs, outputs = model.layers[-2].output)\n",
    "            \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a94a8ddc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 224, 224, 3)]     0         \n",
      "                                                                 \n",
      " block1_conv1 (Conv2D)       (None, 224, 224, 64)      1792      \n",
      "                                                                 \n",
      " block1_conv2 (Conv2D)       (None, 224, 224, 64)      36928     \n",
      "                                                                 \n",
      " block1_pool (MaxPooling2D)  (None, 112, 112, 64)      0         \n",
      "                                                                 \n",
      " block2_conv1 (Conv2D)       (None, 112, 112, 128)     73856     \n",
      "                                                                 \n",
      " block2_conv2 (Conv2D)       (None, 112, 112, 128)     147584    \n",
      "                                                                 \n",
      " block2_pool (MaxPooling2D)  (None, 56, 56, 128)       0         \n",
      "                                                                 \n",
      " block3_conv1 (Conv2D)       (None, 56, 56, 256)       295168    \n",
      "                                                                 \n",
      " block3_conv2 (Conv2D)       (None, 56, 56, 256)       590080    \n",
      "                                                                 \n",
      " block3_conv3 (Conv2D)       (None, 56, 56, 256)       590080    \n",
      "                                                                 \n",
      " block3_pool (MaxPooling2D)  (None, 28, 28, 256)       0         \n",
      "                                                                 \n",
      " block4_conv1 (Conv2D)       (None, 28, 28, 512)       1180160   \n",
      "                                                                 \n",
      " block4_conv2 (Conv2D)       (None, 28, 28, 512)       2359808   \n",
      "                                                                 \n",
      " block4_conv3 (Conv2D)       (None, 28, 28, 512)       2359808   \n",
      "                                                                 \n",
      " block4_pool (MaxPooling2D)  (None, 14, 14, 512)       0         \n",
      "                                                                 \n",
      " block5_conv1 (Conv2D)       (None, 14, 14, 512)       2359808   \n",
      "                                                                 \n",
      " block5_conv2 (Conv2D)       (None, 14, 14, 512)       2359808   \n",
      "                                                                 \n",
      " block5_conv3 (Conv2D)       (None, 14, 14, 512)       2359808   \n",
      "                                                                 \n",
      " block5_pool (MaxPooling2D)  (None, 7, 7, 512)         0         \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 25088)             0         \n",
      "                                                                 \n",
      " fc1 (Dense)                 (None, 4096)              102764544 \n",
      "                                                                 \n",
      " fc2 (Dense)                 (None, 4096)              16781312  \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 134,260,544\n",
      "Trainable params: 134,260,544\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "encoding = image_encodings()\n",
    "encoding.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9c3c209",
   "metadata": {},
   "source": [
    "## L1 Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "694ae94f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Siamese L1 Distance class\n",
    "class L1Dist(Layer):\n",
    "    \n",
    "    # Init method - inheritance\n",
    "    def __init__(self, **kwargs):\n",
    "        super().__init__()\n",
    "       \n",
    "    # Magic happens here - similarity calculation\n",
    "    def call(self, input_embedding, validation_embedding):\n",
    "        return tf.math.abs(input_embedding - validation_embedding)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab7484d9",
   "metadata": {},
   "source": [
    "## Siamese Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8bb75b2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_siamese_model(): \n",
    "    \n",
    "    # Anchor image input in the network\n",
    "    input_image = Input(name='input_img', shape=(224,224,3))\n",
    "    \n",
    "    # Validation image in the network \n",
    "    validation_image = Input(name='validation_img', shape=(224,224,3))\n",
    "    \n",
    "    # Combine siamese distance components\n",
    "    siamese_layer = L1Dist()\n",
    "    siamese_layer._name = 'distance'\n",
    "    distances = siamese_layer(encoding(input_image), encoding(validation_image))\n",
    "    \n",
    "    dense = Dense(512, activation='relu')(distances)\n",
    "    \n",
    "    # Classification layer \n",
    "    classifier = Dense(1, activation='sigmoid')(dense)\n",
    "    \n",
    "    return Model(inputs=[input_image, validation_image], outputs=classifier, name='SiameseNetwork')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b07309f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"SiameseNetwork\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_img (InputLayer)         [(None, 224, 224, 3  0           []                               \n",
      "                                )]                                                                \n",
      "                                                                                                  \n",
      " validation_img (InputLayer)    [(None, 224, 224, 3  0           []                               \n",
      "                                )]                                                                \n",
      "                                                                                                  \n",
      " model (Functional)             (None, 4096)         134260544   ['input_img[0][0]',              \n",
      "                                                                  'validation_img[0][0]']         \n",
      "                                                                                                  \n",
      " distance (L1Dist)              (None, 4096)         0           ['model[0][0]',                  \n",
      "                                                                  'model[1][0]']                  \n",
      "                                                                                                  \n",
      " dense (Dense)                  (None, 512)          2097664     ['distance[0][0]']               \n",
      "                                                                                                  \n",
      " dense_1 (Dense)                (None, 1)            513         ['dense[0][0]']                  \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 136,358,721\n",
      "Trainable params: 136,358,721\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "siamese_model = make_siamese_model()\n",
    "siamese_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f990d6bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.keras.utils.plot_model(\n",
    "    siamese_model,\n",
    "    to_file='model.png',\n",
    "    show_shapes=False,\n",
    "    show_dtype=False,\n",
    "    show_layer_names=True,\n",
    "    rankdir='TB',\n",
    "    expand_nested=False,\n",
    "    dpi=96,\n",
    "    layer_range=None,\n",
    "    show_layer_activations=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "c68424ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "binary_cross_loss = tf.losses.BinaryCrossentropy()\n",
    "opt = tf.keras.optimizers.Adam(1e-4) # 0.0001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "70ea26da",
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_dir = './training_checkpoints'\n",
    "checkpoint_prefix = os.path.join(checkpoint_dir, 'ckpt')\n",
    "checkpoint = tf.train.Checkpoint(opt=opt, siamese_model=siamese_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c389165",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "42c9533e",
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def train_step(batch):\n",
    "    \n",
    "    # Record all of our operations \n",
    "    with tf.GradientTape() as tape:     \n",
    "        # Get anchor and positive/negative image\n",
    "        X = batch[:2]\n",
    "        # Get label\n",
    "        y = batch[2]\n",
    "        \n",
    "        # Forward pass\n",
    "        yhat = siamese_model(X, training=True)\n",
    "        # Calculate loss\n",
    "        loss = binary_cross_loss(y, yhat)\n",
    "    print(loss)\n",
    "        \n",
    "    # Calculate gradients\n",
    "    grad = tape.gradient(loss, siamese_model.trainable_variables)\n",
    "    \n",
    "    # Calculate updated weights and apply to siamese model\n",
    "    opt.apply_gradients(zip(grad, siamese_model.trainable_variables))\n",
    "        \n",
    "    # Return loss\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "893fed68",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import metric calculations\n",
    "from tensorflow.keras.metrics import Precision, Recall\n",
    "def train(data, EPOCHS):\n",
    "    # Loop through epochs\n",
    "    for epoch in range(1, EPOCHS+1):\n",
    "        print('\\n Epoch {}/{}'.format(epoch, EPOCHS))\n",
    "        progbar = tf.keras.utils.Progbar(len(data))\n",
    "        \n",
    "        # Creating a metric object \n",
    "        r = Recall()\n",
    "        p = Precision()\n",
    "        \n",
    "        # Loop through each batch\n",
    "        for idx, batch in enumerate(data):\n",
    "            # Run train step here\n",
    "            loss = train_step(batch)\n",
    "            yhat = siamese_model.predict(batch[:2])\n",
    "            r.update_state(batch[2], yhat)\n",
    "            p.update_state(batch[2], yhat) \n",
    "            progbar.update(idx+1)\n",
    "        print(loss.numpy(), r.result().numpy(), p.result().numpy())\n",
    "        \n",
    "        # Save checkpoints\n",
    "        if epoch % 10 == 0: \n",
    "            checkpoint.save(file_prefix=checkpoint_prefix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "078bd00c",
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 50\n",
    "train(train_data, EPOCHS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "661cbc0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    }
   ],
   "source": [
    "# Save weights\n",
    "siamese_model.save('siamesemodelv2.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07a185f9",
   "metadata": {},
   "source": [
    "# References:\n",
    "1. DeepFace: Closing the Gap to Human-Level Performance in Face Verification\n",
    "2. Nicholas Renotte, https://lnkd.in/gi7fYrUY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b747435",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "adv_maths",
   "language": "python",
   "name": "adv_maths"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
